{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMDB Sentiment Classifier\n",
    "### Using Hugging Face with the SageMaker SDK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Uh Oh\n",
    "\n",
    "If we're here, then something went wrong and we're using an existing real time inference endpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "import boto3\n",
    "import botocore\n",
    "import sagemaker\n",
    "import sagemaker.huggingface\n",
    "from sagemaker.predictor import Predictor\n",
    "from sagemaker.serializers import JSONSerializer\n",
    "from sagemaker.deserializers import JSONDeserializer\n",
    "\n",
    "session = sagemaker.Session()\n",
    "bucket = session.default_bucket()\n",
    "role = sagemaker.get_execution_role()\n",
    "\n",
    "predictor = Predictor(\n",
    "    endpoint_name = \"imdb-huggingface-2021-05-17-18-17-17-517\",\n",
    "    sagemaker_session = session, \n",
    "    serializer = JSONSerializer(), \n",
    "    deserializer = JSONDeserializer()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make Inferences Using a SageMaker Predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas\n",
    "\n",
    "inputs = [\n",
    "    \"Willow is the greatest movie that ever lived.\",\n",
    "    \"The Notebook is ironically depressing.\",\n",
    "    \"It's annoying that I had to Google the capitalization of 'Back to the Future', but it is a gem of nostalgic wonder.\",\n",
    "    \"Yikes! Weird Science did not age well for 2021.\",\n",
    "    \"Love and Monsters made me cry happy tears.\"\n",
    "]\n",
    "\n",
    "results = []\n",
    "for it in inputs:\n",
    "    inp = {\"text\": it}\n",
    "    prediction = predictor.predict(inp)\n",
    "    results.append({\n",
    "        **inp,\n",
    "        **prediction\n",
    "    })\n",
    "    \n",
    "df = pandas.DataFrame(results)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Load a Pre-Trained Model from S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch\n",
    "import tarfile\n",
    "\n",
    "model_s3_path = \"s3://sagemaker-us-east-1-934284400219/imdb-huggingface-2021-05-17-18-17-17-517/model.tar.gz\"\n",
    "\n",
    "sagemaker.s3.S3Downloader.download(model_s3_path, \"models\")\n",
    "\n",
    "with tarfile.open(\"models/model.tar.gz\") as f:\n",
    "    f.extractall(path = \"models/\")\n",
    "    f.close()\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"./models\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(input_text):\n",
    "    CLASS_NAMES = [\"NEGATIVE\", \"POSITIVE\"]\n",
    "    tokenized = tokenizer(\n",
    "        input_text,\n",
    "        add_special_tokens = True,\n",
    "        return_token_type_ids = False,\n",
    "        return_attention_mask = True,\n",
    "        padding = \"max_length\",\n",
    "        truncation = True,\n",
    "        return_tensors = \"pt\"\n",
    "    )\n",
    "    output = model(tokenized[\"input_ids\"], tokenized[\"attention_mask\"])\n",
    "    values, indices = torch.max(output.logits, dim = 1)\n",
    "    normalized = torch.softmax(output.logits, dim = 1)\n",
    "    index = indices.item()\n",
    "    confidence = normalized[0][index].item()\n",
    "    return {\n",
    "        \"text\": input_text,\n",
    "        \"sentiment\": CLASS_NAMES[index],\n",
    "        \"confidence\": confidence\n",
    "    }\n",
    "\n",
    "df = pandas.DataFrame([predict(it) for it in inputs])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.g4dn.xlarge",
  "kernelspec": {
   "display_name": "Python 3 (PyTorch 1.6 Python 3.6 GPU Optimized)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/pytorch-1.6-gpu-py36-cu110-ubuntu18.04-v3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
