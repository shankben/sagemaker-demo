{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMDB Sentiment Classifier\n",
    "### Using Hugging Face with the SageMaker SDK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What We're Going To Do:\n",
    "\n",
    "#### Installation\n",
    "1. Install the SageMaker SDK and the Hugging Face libraries\n",
    "1. Start a SageMaker session, including the default IAM role and S3 bucket\n",
    "    \n",
    "#### Data Preparation\n",
    "1. Tokenization: Download and prepare our IMDB dataset for NLP model training\n",
    "1. Upload our tokenized and split dataset to S3\n",
    "\n",
    "#### Model Training\n",
    "1. Setup an Estimator\n",
    "1. Train a model\n",
    "\n",
    "#### Real Time Inference\n",
    "1. Prepare the model for deployment\n",
    "1. Deploy the model and create a Predictor\n",
    "1. Make inferences using a Predictor\n",
    "\n",
    "#### Clean Up"
   ]
  },
  {
   "attachments": {
    "what-is-ml.svg": {
     "image/svg+xml": [
      "<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE svg PUBLIC "-//W3C//DTD SVG 1.1//EN" "http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd">
<svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" version="1.1" width="336px" height="425px" viewBox="-0.5 -0.5 336 425" content="&lt;mxfile host=&quot;Electron&quot; modified=&quot;2021-05-17T13:25:46.785Z&quot; agent=&quot;5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) draw.io/14.6.13 Chrome/89.0.4389.128 Electron/12.0.7 Safari/537.36&quot; etag=&quot;crTZht76QfDrV0jaZEQi&quot; version=&quot;14.6.13&quot; type=&quot;device&quot;&gt;&lt;diagram id=&quot;-nsVYrA13-EjBoEKal0-&quot; name=&quot;Page-1&quot;&gt;5Vpbc9o4FP41zLQP2bHlC+YxQNqd2XTaSbbT9lHYwlZXWF5ZDrC/fiVbxhfZQAIOtEkesI6ko6PvfN+RuIys2WrzkcEk+kQDREbACDYjaz4CwLTHhniRlq2yOMArLCHDgbJVhkf8H1JGNTHMcIDSxkBOKeE4aRp9GsfI5w0bZIyum8OWlDRXTWCINMOjD4lu/YYDHimraxhVx58Ih1G5NCh7VrAcrQxpBAO6rpmsu5E1Y5Ty4mm1mSEi4SuBKeZ96OndRcZQzI+ZgL8+/D3fMvD5y4fwPqBPxl8P8EZ5eYIkUzueQw5VwHxbwiA8CcRFY7qOMEePCfRlz1pkXdgiviKiZYpHmCZFGpZ4g8TC0yUmZEYJZbkjK3CQF9jCnnJG/0G1Hg8sLNeVM2jMFRFM2VYRIsbRpnfr5g5QwUVEV4izrRiiJthlUhQNd0laVzn1lCmqZbO0QcWicOe5wlk8KKifATvQYP+c8STjwwG/XCLX97uAD8aThcBjEOBd+8qAd3WEAyF41aSMRzSkMSR3lXXKaBYHEtO5RKkac09potD/iTjfKuxgxmkzN2iD+ffa8w/p6g9HteYb5TlvbFWjnQwBONt+L0fKRs2LbFZu8lbpp9iv3OT+FIq6ClmI+CHS6qlmiECOn5r+uxKnpn6hWKxcUaStTbuV+5RmzEdqVr2+tR2Nm44ss+Wo2KDmKOfRbj8vp5ajaVrnWhzcykNJtHwC0xT7pxPlpcToVvsxRCkScvhQOUgo0+1mVK04OB3FobSdSLwxaPLFM15IPAccYPDAxDM7iHadRe0KuTo+kquTcxQ/IX64rQ1IJCXSforakyazbMvYy0RtvGe0CFdEcFb6jd/kFdKaXPgmY1q/iuoHVK83yJWkXdDtdhJ7Cvqp8nbsK5S3p8n793yr0ha4c+m3KqapQ3ydAr/CY31y7BXU6CbF0RXkpBRPNG19gn6EYySM9wiyGMehRoJT1eXI/y51ufnfMOrSSqp9aXUZGvYPGUHpgPcWiLxlZ1lzfQ8tlq/zCczlgbc14EfAJVxtvwG++29Gy46bNAfmVgwAdrKpOsVTqF5zL4u2Qbn1d4BXM8sro+ZsF5PYYzG/9Gkc41ZltCPG6WmO++K1DrsVPRU0uds2XEdFoM5gLQKnN4KO5fuGtrQnaM+bImtqJ6YxaglNmSDBYSyavpAJEvapFBH2IblVHSscBKRP1c1TtKZKYJ/psmE6DVWarq5KMOmQJRhMlu7bqIfahzUXv+bp75/PUw/fvaye9C23VmDIBRfya7Rn1Mx6HKVtdtTo4aMWr3AlqRsv0mRfbXrdsPoL+m8EZprA+DnLFV9olNuQdhYu3gFZTI0cBMN0qmfj/f5Tqli9sL+/XEh7MKtHWDuyn3c8v1o2B02yaXgVojaonidmJ6a9ML7ZO4bVccewwHnuGKJZ/ZCh+OSp+kGIdfc/&lt;/diagram&gt;&lt;/mxfile&gt;" style="background-color: rgb(255, 255, 255);"><defs/><g><ellipse cx="40" cy="84" rx="40" ry="40" fill="#d5e8d4" stroke="#82b366" pointer-events="all"/><g transform="translate(-0.5 -0.5)"><switch><foreignObject style="overflow: visible; text-align: left;" pointer-events="none" width="100%" height="100%" requiredFeatures="http://www.w3.org/TR/SVG11/feature#Extensibility"><div xmlns="http://www.w3.org/1999/xhtml" style="display: flex; align-items: unsafe center; justify-content: unsafe center; width: 78px; height: 1px; padding-top: 84px; margin-left: 1px;"><div style="box-sizing: border-box; font-size: 0; text-align: center; "><div style="display: inline-block; font-size: 16px; font-family: Helvetica; color: #000000; line-height: 1.2; pointer-events: all; white-space: normal; word-wrap: normal; ">Data</div></div></div></foreignObject><text x="40" y="89" fill="#000000" font-family="Helvetica" font-size="16px" text-anchor="middle">Data</text></switch></g><ellipse cx="280" cy="84" rx="40" ry="40" fill="#ffe6cc" stroke="#d79b00" pointer-events="all"/><g transform="translate(-0.5 -0.5)"><switch><foreignObject style="overflow: visible; text-align: left;" pointer-events="none" width="100%" height="100%" requiredFeatures="http://www.w3.org/TR/SVG11/feature#Extensibility"><div xmlns="http://www.w3.org/1999/xhtml" style="display: flex; align-items: unsafe center; justify-content: unsafe center; width: 78px; height: 1px; padding-top: 84px; margin-left: 241px;"><div style="box-sizing: border-box; font-size: 0; text-align: center; "><div style="display: inline-block; font-size: 16px; font-family: Helvetica; color: #000000; line-height: 1.2; pointer-events: all; white-space: normal; word-wrap: normal; ">Output</div></div></div></foreignObject><text x="280" y="89" fill="#000000" font-family="Helvetica" font-size="16px" text-anchor="middle">Output</text></switch></g><path d="M 200 84 L 233.63 84" fill="none" stroke="#000000" stroke-miterlimit="10" pointer-events="stroke"/><path d="M 238.88 84 L 231.88 87.5 L 233.63 84 L 231.88 80.5 Z" fill="#000000" stroke="#000000" stroke-miterlimit="10" pointer-events="all"/><path d="M 80 84 L 113.63 84" fill="none" stroke="#000000" stroke-miterlimit="10" pointer-events="stroke"/><path d="M 118.88 84 L 111.88 87.5 L 113.63 84 L 111.88 80.5 Z" fill="#000000" stroke="#000000" stroke-miterlimit="10" pointer-events="all"/><path d="M 80 274 L 90 274 L 90 324 L 113.63 324" fill="none" stroke="#000000" stroke-miterlimit="10" pointer-events="stroke"/><path d="M 118.88 324 L 111.88 327.5 L 113.63 324 L 111.88 320.5 Z" fill="#000000" stroke="#000000" stroke-miterlimit="10" pointer-events="all"/><ellipse cx="40" cy="274" rx="40" ry="40" fill="#d5e8d4" stroke="#82b366" pointer-events="all"/><g transform="translate(-0.5 -0.5)"><switch><foreignObject style="overflow: visible; text-align: left;" pointer-events="none" width="100%" height="100%" requiredFeatures="http://www.w3.org/TR/SVG11/feature#Extensibility"><div xmlns="http://www.w3.org/1999/xhtml" style="display: flex; align-items: unsafe center; justify-content: unsafe center; width: 78px; height: 1px; padding-top: 274px; margin-left: 1px;"><div style="box-sizing: border-box; font-size: 0; text-align: center; "><div style="display: inline-block; font-size: 16px; font-family: Helvetica; color: #000000; line-height: 1.2; pointer-events: all; white-space: normal; word-wrap: normal; ">Data</div></div></div></foreignObject><text x="40" y="279" fill="#000000" font-family="Helvetica" font-size="16px" text-anchor="middle">Data</text></switch></g><path d="M 80 384 L 90 384 L 90 324 L 113.63 324" fill="none" stroke="#000000" stroke-miterlimit="10" pointer-events="stroke"/><path d="M 118.88 324 L 111.88 327.5 L 113.63 324 L 111.88 320.5 Z" fill="#000000" stroke="#000000" stroke-miterlimit="10" pointer-events="all"/><ellipse cx="40" cy="384" rx="40" ry="40" fill="#ffe6cc" stroke="#d79b00" pointer-events="all"/><g transform="translate(-0.5 -0.5)"><switch><foreignObject style="overflow: visible; text-align: left;" pointer-events="none" width="100%" height="100%" requiredFeatures="http://www.w3.org/TR/SVG11/feature#Extensibility"><div xmlns="http://www.w3.org/1999/xhtml" style="display: flex; align-items: unsafe center; justify-content: unsafe center; width: 78px; height: 1px; padding-top: 384px; margin-left: 1px;"><div style="box-sizing: border-box; font-size: 0; text-align: center; "><div style="display: inline-block; font-size: 16px; font-family: Helvetica; color: #000000; line-height: 1.2; pointer-events: all; white-space: normal; word-wrap: normal; ">Output</div></div></div></foreignObject><text x="40" y="389" fill="#000000" font-family="Helvetica" font-size="16px" text-anchor="middle">Output</text></switch></g><path d="M 200 324 L 233.63 324" fill="none" stroke="#000000" stroke-miterlimit="10" pointer-events="stroke"/><path d="M 238.88 324 L 231.88 327.5 L 233.63 324 L 231.88 320.5 Z" fill="#000000" stroke="#000000" stroke-miterlimit="10" pointer-events="all"/><rect x="120" y="284" width="80" height="80" fill="#f5f5f5" stroke="#666666" pointer-events="all"/><g transform="translate(-0.5 -0.5)"><switch><foreignObject style="overflow: visible; text-align: left;" pointer-events="none" width="100%" height="100%" requiredFeatures="http://www.w3.org/TR/SVG11/feature#Extensibility"><div xmlns="http://www.w3.org/1999/xhtml" style="display: flex; align-items: unsafe center; justify-content: unsafe center; width: 78px; height: 1px; padding-top: 324px; margin-left: 121px;"><div style="box-sizing: border-box; font-size: 0; text-align: center; "><div style="display: inline-block; font-size: 16px; font-family: Helvetica; color: #000000; line-height: 1.2; pointer-events: all; white-space: normal; word-wrap: normal; ">Machine Learning</div></div></div></foreignObject><text x="160" y="329" fill="#000000" font-family="Helvetica" font-size="16px" text-anchor="middle">Machine Le...</text></switch></g><ellipse cx="280" cy="324" rx="40" ry="40" fill="#dae8fc" stroke="#6c8ebf" pointer-events="all"/><g transform="translate(-0.5 -0.5)"><switch><foreignObject style="overflow: visible; text-align: left;" pointer-events="none" width="100%" height="100%" requiredFeatures="http://www.w3.org/TR/SVG11/feature#Extensibility"><div xmlns="http://www.w3.org/1999/xhtml" style="display: flex; align-items: unsafe center; justify-content: unsafe center; width: 78px; height: 1px; padding-top: 324px; margin-left: 241px;"><div style="box-sizing: border-box; font-size: 0; text-align: center; "><div style="display: inline-block; font-size: 16px; font-family: Helvetica; color: #000000; line-height: 1.2; pointer-events: all; white-space: normal; word-wrap: normal; ">Rules</div></div></div></foreignObject><text x="280" y="329" fill="#000000" font-family="Helvetica" font-size="16px" text-anchor="middle">Rules</text></switch></g><rect x="15" y="4" width="290" height="20" fill="none" stroke="none" pointer-events="all"/><g transform="translate(-0.5 -0.5)"><switch><foreignObject style="overflow: visible; text-align: left;" pointer-events="none" width="100%" height="100%" requiredFeatures="http://www.w3.org/TR/SVG11/feature#Extensibility"><div xmlns="http://www.w3.org/1999/xhtml" style="display: flex; align-items: unsafe center; justify-content: unsafe center; width: 288px; height: 1px; padding-top: 14px; margin-left: 16px;"><div style="box-sizing: border-box; font-size: 0; text-align: center; "><div style="display: inline-block; font-size: 24px; font-family: Helvetica; color: #000000; line-height: 1.2; pointer-events: all; white-space: normal; word-wrap: normal; "><font style="font-size: 24px"><b><font color="#82b366">2</font> <font color="#6c8ebf">+</font> <font color="#82b366">3</font> </b>=<b> <font color="#d79b00">5</font></b></font></div></div></div></foreignObject><text x="160" y="21" fill="#000000" font-family="Helvetica" font-size="24px" text-anchor="middle">2 + 3 = 5</text></switch></g><ellipse cx="160" cy="84" rx="40" ry="40" fill="#dae8fc" stroke="#6c8ebf" pointer-events="all"/><g transform="translate(-0.5 -0.5)"><switch><foreignObject style="overflow: visible; text-align: left;" pointer-events="none" width="100%" height="100%" requiredFeatures="http://www.w3.org/TR/SVG11/feature#Extensibility"><div xmlns="http://www.w3.org/1999/xhtml" style="display: flex; align-items: unsafe center; justify-content: unsafe center; width: 78px; height: 1px; padding-top: 84px; margin-left: 121px;"><div style="box-sizing: border-box; font-size: 0; text-align: center; "><div style="display: inline-block; font-size: 16px; font-family: Helvetica; color: #000000; line-height: 1.2; pointer-events: all; white-space: normal; word-wrap: normal; ">Rules</div></div></div></foreignObject><text x="160" y="89" fill="#000000" font-family="Helvetica" font-size="16px" text-anchor="middle">Rules</text></switch></g><rect x="15" y="204" width="320" height="20" fill="none" stroke="none" pointer-events="all"/><g transform="translate(-0.5 -0.5)"><switch><foreignObject style="overflow: visible; text-align: left;" pointer-events="none" width="100%" height="100%" requiredFeatures="http://www.w3.org/TR/SVG11/feature#Extensibility"><div xmlns="http://www.w3.org/1999/xhtml" style="display: flex; align-items: unsafe center; justify-content: unsafe center; width: 318px; height: 1px; padding-top: 214px; margin-left: 16px;"><div style="box-sizing: border-box; font-size: 0; text-align: center; "><div style="display: inline-block; font-size: 24px; font-family: Helvetica; color: #000000; line-height: 1.2; pointer-events: all; white-space: normal; word-wrap: normal; "><font style="font-size: 24px">(<font color="#82b366" style="font-weight: bold">2</font><font>,</font><font color="#82b366" style="font-weight: bold"> </font><font color="#82b366" style="font-weight: bold">3</font><font>,</font><font color="#82b366" style="font-weight: bold"> </font><span style="font-weight: bold ; color: rgb(215 , 155 , 0)">5</span>)<span style="font-weight: bold ; color: rgb(215 , 155 , 0)"> </span>=<font color="#d79b00" style="font-weight: bold"> </font></font><span style="font-weight: bold ; color: rgb(108 , 142 , 191)">+</span></div></div></div></foreignObject><text x="175" y="221" fill="#000000" font-family="Helvetica" font-size="24px" text-anchor="middle">(2, 3, 5) = +</text></switch></g></g><switch><g requiredFeatures="http://www.w3.org/TR/SVG11/feature#Extensibility"/><a transform="translate(0,-5)" xlink:href="https://www.diagrams.net/doc/faq/svg-export-text-problems" target="_blank"><text text-anchor="middle" font-size="10px" x="50%" y="100%">Viewer does not support full SVG 1.1</text></a></switch></svg>"
     ]
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# But What _Is_ Machine Learning?\n",
    "\n",
    "For our purposes, we can think of machine learning as a method of using computers to learn the rules of computation. \n",
    "\n",
    "For example, in a traditional computation like adding two integers, we supply the input data, the integers 2 and 3, and wish to apply a rule, addition, to compute the output, 5. Computers are convenient for these types of operations for obvious historical reasons.\n",
    "\n",
    "However, with machine learning, we supply the input and output data, but are interested in computing the unknown rules that generated our output from the input. This process is not magic. Behind the scenes, machine learning relies on statistical techniques and often complex framing of the problem as one of optimizing the fit of rules that minimize the error between the input and output data. Both how this optimization problem is framed and what particular mechanisms are employed to use computers to fit optimized rules to the data is at the frontier of machine learning research. \n",
    "\n",
    "Due to the increasingly convenient and economical benefits of cloud computing of the past decade, machine learning has become more accessible and democratized. However, to perform machine learning in a cloud environment, one is still responsible for the data preparation, training, and inference infrastructure. This is where Amazon SageMaker is beneficial. It's a machine learning service that you can use to build, train, and deploy machine learning models for virtually any use case.\n",
    "\n",
    "![diagram](assets/what-is-ml.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Installation\n",
    "##### ⏰ About 1 minute\n",
    "\n",
    "This section has nothing to do with machine learning, but sets up our development environment with the requisite SDKs and AWS constructs we'll need to perform machine learning. In particular, we'll fix specific versions of the SageMaker and Hugging Face SDKs, as well as direct our SageMaker Studio session to use a particular S3 bucket for staging our input and output data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "%%capture\n",
    "\n",
    "import os\n",
    "\n",
    "DATASETS_VERSION = \"1.6.2\"\n",
    "TRANSFORMERS_VERSION = \"4.5.0\"\n",
    "SAGEMAKER_VERSION = \"2.40.0\"\n",
    "\n",
    "requirements_txt = f\"\"\"numpy\n",
    "pandas\n",
    "transformers=={TRANSFORMERS_VERSION}\n",
    "datasets=={DATASETS_VERSION}\n",
    "\"\"\"\n",
    "\n",
    "with open(os.path.join(os.getcwd(), \"scripts\", \"requirements.txt\"), \"w\") as f:\n",
    "    f.write(requirements_txt)\n",
    "\n",
    "!pip install --upgrade \"sagemaker==$SAGEMAKER_VERSION\" \"transformers==$TRANSFORMERS_VERSION\" \"datasets[s3]==$DATASETS_VERSION\"\n",
    "# !conda install -c conda-forge ipywidgets -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    import IPython\n",
    "    IPython.Application.instance().kernel.do_shutdown(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "import boto3\n",
    "import botocore\n",
    "import sagemaker\n",
    "import sagemaker.huggingface\n",
    "\n",
    "session = sagemaker.Session()\n",
    "bucket = session.default_bucket()\n",
    "role = sagemaker.get_execution_role()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"SageMaker role arn: {role}\")\n",
    "print(f\"SageMaker bucket: {session.default_bucket()}\")\n",
    "print(f\"SageMaker session region: {session.boto_region_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download and Split the Dataset\n",
    "##### ⏰ About 2 minutes\n",
    "\n",
    "Machine learning datasets are often a mixture of labeled and unlabeled data. For this example, we'll only be using labeled from the IMDB movie reviews. \n",
    "\n",
    "When a model is trained, the process feeds labeled examples from our dataset into the training algorithm, which evaluates its performance against other labeled examples in the dataset. If the model is doing well, then the error between its predictions and the test data will be low. But we need to first decide how much of our dataset will be used for training and how much will be used for evaluating the model as it is trained. For our example, we'll simply split the labeled dataset in half and use one half for training and the other for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "import pandas\n",
    "import datasets\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "model_name = \"distilbert-base-uncased\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "train_dataset, test_dataset = datasets.load_dataset(\n",
    "    \"imdb\", \n",
    "    ignore_verifications = False,\n",
    "    split = [\"train\", \"test\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenization\n",
    "##### ⏰ About 1 minute\n",
    "\n",
    "NLP models are not trained directly against the natural languages they form predictions over. Generally speaking, machine learning models are trained with numerical inputs. Tokenization is the data preparation process by which we take our natural English language movie reviews and transform them into numbers the model training algorithm understands. There are many different ways to tokenize natural language data. In our case we will select the tokenizer that was originally used for training the pretrained [DiltilBERT model Hugging Face provides](https://huggingface.co/distilbert-base-uncased)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "tokenize = lambda batch: tokenizer(\n",
    "    batch[\"text\"], \n",
    "    padding = \"max_length\", \n",
    "    truncation = \"longest_first\"\n",
    ")\n",
    "\n",
    "train_ds = train_dataset.shuffle().map(tokenize)\n",
    "test_ds = test_dataset.shuffle().map(tokenize)\n",
    "\n",
    "try:\n",
    "    train_ds = train_ds.rename_column(\"label\", \"labels\")\n",
    "    test_ds = test_ds.rename_column(\"label\", \"labels\")\n",
    "except:\n",
    "    pass\n",
    "\n",
    "columns = [\"input_ids\", \"attention_mask\", \"labels\"]\n",
    "train_ds.set_format(\"torch\", columns = columns)\n",
    "test_ds.set_format(\"torch\", columns = columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### So What Does a Tokenized Natural Language Dataset Look Like?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds.to_pandas().head(100)[[\"text\", \"labels\", \"input_ids\", \"attention_mask\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### WTF?\n",
    "\n",
    "- `text` contains the raw English IMDB movie reviews \n",
    "- `labels` are the sentiment values for each review where `1` is positive and `0` is negative\n",
    "- `input_ids` are the tokens, referred to here as IDs. Hugging Face associates the token IDs with the raw numerical token values that are fed into the model training loop.\n",
    "- `attention_mask` refers to which elements of the `input_ids` vector are actually processed in the training loop. Because each original `text` is a different length, we've chosen to pad the data to the same length. The attention mask makes sure the empty padding values are not used in the training loop."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upload the Dataset to S3\n",
    "##### ⏰ About 5 seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "from datasets.filesystems import S3FileSystem\n",
    "\n",
    "s3 = S3FileSystem()\n",
    "\n",
    "s3_prefix = \"datasets/imdb-binary-classification\"\n",
    "training_input_path = f\"s3://{bucket}/{s3_prefix}/train\"\n",
    "test_input_path = f\"s3://{bucket}/{s3_prefix}/test\"\n",
    "\n",
    "train_ds.save_to_disk(training_input_path, fs = s3)\n",
    "test_ds.save_to_disk(test_input_path, fs = s3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-size: 16px;\"><a href=\"https://s3.console.aws.amazon.com/s3/buckets/sagemaker-us-east-1-934284400219?region=us-east-1&prefix=datasets/imdb-binary-classification/&showversions=false\">Prove it Landed in S3</a></span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup an Estimator\n",
    "\n",
    "Estimators are part of the SageMaker SDK and represent at a high-level the model training job, data access, and managed infrastructure required to produce the trained model artifact. Using the latest version of the SageMaker SDK, we can leverage its [Hugging Face integration](https://huggingface.co/blog/the-partnership-amazon-sagemaker-and-hugging-face) to simplify the training process.\n",
    "\n",
    "How do we evaluate the model training performance as its running? When we train a model using SageMaker, we can monitor several metrics in real time in AWS using Amazon CloudWatch. In particular, we'll look at two varieties of metrics: the EC2 training instance metrics and the training algorithm metrics. The EC2 training instance metrics will be supplied by SageMaker without needing to configure anything. But to capture the specific Hugging Face model training metrics, we need to tell the `HuggingFace` estimator that we're interested in specific ones, which we do by specifiying in the `metric_definitions` list below. There are many more detailed metrics we can subscribe to, but for this example we will only pay attention to two: the epoch and the loss. \n",
    "\n",
    "Loosely speaking, when we train a machine learning model over a dataset, one complete run through the dataset is called an _epoch_. Usually models are trained for more than one epoch, and in our case we will train for three epochs. The _loss_ is a generalized notion of the error associated with the model's performance against the test dataset we split from the training set at the beginning of this notebook. The lower the loss is, the better our model is at predicting correct sentiment labels on the test dataset, which it has never seen before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sagemaker.huggingface import HuggingFace\n",
    "\n",
    "job_name = \"imdb-huggingface\"\n",
    "\n",
    "estimator = HuggingFace(\n",
    "    base_job_name = job_name,\n",
    "    role = role,\n",
    "    py_version = \"py36\",\n",
    "    pytorch_version = \"1.6.0\",\n",
    "    transformers_version = TRANSFORMERS_VERSION,\n",
    "    entry_point = \"trainer.py\",\n",
    "    instance_count = 1,\n",
    "    instance_type = \"ml.p3.16xlarge\",\n",
    "    source_dir = \"./scripts\",\n",
    "    enable_sagemaker_metrics = True,\n",
    "    metric_definitions = [\n",
    "        { \"Name\": \"epoch\", \"Regex\": \"'epoch': ([0-9]+(.|e\\-)[0-9]+),?\" },\n",
    "        { \"Name\": \"loss\", \"Regex\": \"'loss': ([0-9]+(.|e\\-)[0-9]+),?\" }\n",
    "    ],\n",
    "    hyperparameters = {\n",
    "        \"epochs\": 3,\n",
    "        \"eval_batch_size\": 32,\n",
    "        \"model_name\": model_name,\n",
    "        \"train_batch_size\": 32\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-size: 16px;\"><a href=\"https://console.aws.amazon.com/sagemaker/home?region=us-east-1#/jobs/\">See Training Jobs in the SageMaker Console</a></span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train a Model using the Estimator\n",
    "##### ⏰ About 15 minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "inputs = {\n",
    "    \"train\": training_input_path, \n",
    "    \"test\": test_input_path\n",
    "}\n",
    "estimator.fit(inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How'd It Go?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker import TrainingJobAnalytics\n",
    "df = TrainingJobAnalytics(training_job_name = estimator.latest_training_job.name).dataframe()\n",
    "df = df[[\"metric_name\", \"value\"]]\n",
    "\n",
    "summary = df.groupby(\"metric_name\").describe()\n",
    "summary.columns = summary.columns.droplevel(0)\n",
    "summary = summary.reset_index().rename(columns = { \n",
    "    \"metric_name\": \"Metric\",\n",
    "    \"min\": \"Min\", \n",
    "    \"max\": \"Max\", \n",
    "    \"mean\": \"Average\" \n",
    "}).set_index(\"Metric\")\n",
    "summary = summary.drop([\"std\", \"count\", \"25%\", \"50%\", \"75%\"], axis = 1).drop([\"epoch\"])\n",
    "display(summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Model Deployment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare the Model for Deployment\n",
    "\n",
    "Here we use PyTorch for hosting the inference endpoint. The SageMaker SDK comes prebuilt with a PyTorch model class that let's us easily deploy the model to a real time inference endpoint. Because Hugging Face models are compatible with PyTorch, we can simply pass along the reference to the trained model artifacts in S3 to the PyTorchModel object we create below.\n",
    "\n",
    "When we setup this SageMaker model, we need to supply a script that is used when the inference endpoint is invoked. Some models do not need this level of customization, but we want to make sure that our model uses JSON as an input and output format, as well as perform the low level predictions in a particular way, which is coded in the `predictor.py` script included in this project and passed along to our PyTorchModel object below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sagemaker.utils import name_from_base\n",
    "from sagemaker.pytorch import PyTorchModel\n",
    "from sagemaker.predictor import Predictor\n",
    "from sagemaker.serializers import JSONSerializer\n",
    "from sagemaker.deserializers import JSONDeserializer\n",
    "\n",
    "class SentimentAnalysis(Predictor):\n",
    "    def __init__(self, endpoint_name, sagemaker_session):\n",
    "        super().__init__(\n",
    "            endpoint_name, \n",
    "            sagemaker_session = sagemaker_session, \n",
    "            serializer = JSONSerializer(), \n",
    "            deserializer = JSONDeserializer()\n",
    "        )\n",
    "\n",
    "name = name_from_base(job_name)\n",
    "\n",
    "model = PyTorchModel(\n",
    "    name = name,\n",
    "    role = role, \n",
    "    model_data = estimator.model_data,\n",
    "    source_dir = \"./scripts\",\n",
    "    entry_point = \"predictor.py\",\n",
    "    framework_version = \"1.6.0\",\n",
    "    py_version = \"py36\",\n",
    "    predictor_cls = SentimentAnalysis\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-size: 16px;\"><a href=\"https://console.aws.amazon.com/sagemaker/home?region=us-east-1#/endpoints\">See Endpoints in the SageMaker Console</a></span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deploy the Model\n",
    "##### ⏰ About 5 minutes\n",
    "\n",
    "Now that we've configured our model, all that is left is to deploy it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "predictor = model.deploy(\n",
    "    initial_instance_count = 1,\n",
    "    instance_type = \"ml.m5.large\",\n",
    "    endpoint_name = name,\n",
    "    wait = True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make Inferences Using a SageMaker Predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "inputs = [\n",
    "    \"Willow is the greatest movie that ever lived.\",\n",
    "    \"The Notebook is ironically depressing.\",\n",
    "    \"It's annoying that I had to Google the capitalization of 'Back to the Future', but it is a gem of nostalgic wonder.\",\n",
    "    \"Yikes! Weird Science did not age well for 2021.\",\n",
    "    \"Love and Monsters made me cry happy tears.\"\n",
    "]\n",
    "\n",
    "results = []\n",
    "for it in inputs:\n",
    "    inp = {\"text\": it}\n",
    "    prediction = predictor.predict(inp)\n",
    "    results.append({\n",
    "        **inp,\n",
    "        **prediction\n",
    "    })\n",
    "    \n",
    "df = pandas.DataFrame(results)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Clean Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    predictor.delete_endpoint()\n",
    "    model.delete_model()\n",
    "except:\n",
    "    display(\"Already deleted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "sagemaker.s3.S3Downloader.download(estimator.model_data, \"models\")\n",
    "\n",
    "\n",
    "lt = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
    "lm = AutoModelForSequenceClassification.from_pretrained(\"./models\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "tokenized = lt(\n",
    "    inputs[0],\n",
    "    add_special_tokens = True,\n",
    "    return_token_type_ids = False,\n",
    "    return_attention_mask = True,\n",
    "    padding = \"max_length\",\n",
    "    truncation = True,\n",
    "    return_tensors = \"pt\"\n",
    ")\n",
    "prediction = lm(tokenized[\"input_ids\"], tokenized[\"attention_mask\"])\n",
    "\n",
    "# print(\n",
    "#     prediction.logits, '\\n\\n',\n",
    "#     torch.softmax(prediction.logits, dim = 1), '\\n\\n',\n",
    "#     torch.max(prediction.logits, dim = 1)\n",
    "# )\n",
    "\n",
    "values, indices = torch.max(prediction.logits, dim = 1)\n",
    "p = torch.softmax(prediction.logits, dim = 1)\n",
    "\n",
    "print(p[0].size())\n",
    "print(p[0][indices.item()].item(), [\"yes\", \"no\"][indices.item()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.g4dn.xlarge",
  "kernelspec": {
   "display_name": "Python 3 (PyTorch 1.6 Python 3.6 GPU Optimized)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/pytorch-1.6-gpu-py36-cu110-ubuntu18.04-v3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
